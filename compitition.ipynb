{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file from data folder \n",
    "df = pd.read_csv(r'data\\playground-series-s4e7\\train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random sample of data from the dataframe\n",
    "sample_size = 1000\n",
    "df_sample = df.sample(sample_size,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering:\n",
    "    def __init__(self,df_sample):\n",
    "        self.df_sample = df_sample\n",
    "        #map vehicle age to 0,1,2\n",
    "        df_sample['Vehicle_Age'] = df_sample['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})\n",
    "        \n",
    "    def all_clusters(self):\n",
    "        df_sample = self.df_sample\n",
    "        #Based on gender\n",
    "        df_sample_male = df_sample[df_sample['Gender'] == 'Male']\n",
    "        df_sample_female = df_sample[df_sample['Gender'] == 'Female']\n",
    "\n",
    "        #Based on license\n",
    "        df_sample_male_driving = df_sample_male[df_sample_male['Driving_License'] == 1]\n",
    "        df_sample_male_not_driving = df_sample_male[df_sample_male['Driving_License'] == 0]\n",
    "\n",
    "        df_sample_female_driving = df_sample_female[df_sample_female['Driving_License'] == 1]\n",
    "        df_sample_female_not_driving = df_sample_female[df_sample_female['Driving_License'] == 0]\n",
    "\n",
    "\n",
    "\n",
    "        #Based on Previously Insured\n",
    "        df_sample_male_driving_previously_insured = df_sample_male_driving[df_sample_male_driving['Previously_Insured'] == 1]\n",
    "        df_sample_male_driving_not_previously_insured = df_sample_male_driving[df_sample_male_driving['Previously_Insured'] == 0]\n",
    "\n",
    "        df_sample_male_not_driving_previously_insured = df_sample_male_not_driving[df_sample_male_not_driving['Previously_Insured'] == 1]\n",
    "        df_sample_male_not_driving_not_previously_insured = df_sample_male_not_driving[df_sample_male_not_driving['Previously_Insured'] == 0]\n",
    "\n",
    "\n",
    "        df_sample_female_driving_previously_insured = df_sample_female_driving[df_sample_female_driving['Previously_Insured'] == 1]\n",
    "        df_sample_female_driving_not_previously_insured = df_sample_female_driving[df_sample_female_driving['Previously_Insured'] == 0]\n",
    "\n",
    "        df_sample_female_not_driving_previously_insured = df_sample_female_not_driving[df_sample_female_not_driving['Previously_Insured'] == 1]\n",
    "        df_sample_female_not_driving_not_previously_insured = df_sample_female_not_driving[df_sample_female_not_driving['Previously_Insured'] == 0]\n",
    "\n",
    "        #Based on Vehicle Age\n",
    "        df_sample_male_driving_previously_insured_less1 = df_sample_male_driving_previously_insured[df_sample_male_driving_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_male_driving_previously_insured_1to2 = df_sample_male_driving_previously_insured[df_sample_male_driving_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_male_driving_previously_insured_more2 = df_sample_male_driving_previously_insured[df_sample_male_driving_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "        df_sample_male_driving_not_previously_insured_less1 = df_sample_male_driving_not_previously_insured[df_sample_male_driving_not_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_male_driving_not_previously_insured_1to2 = df_sample_male_driving_not_previously_insured[df_sample_male_driving_not_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_male_driving_not_previously_insured_more2 = df_sample_male_driving_not_previously_insured[df_sample_male_driving_not_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "\n",
    "        df_sample_male_not_driving_previously_insured_less1 = df_sample_male_not_driving_previously_insured[df_sample_male_not_driving_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_male_not_driving_previously_insured_1to2 = df_sample_male_not_driving_previously_insured[df_sample_male_not_driving_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_male_not_driving_previously_insured_more2 = df_sample_male_not_driving_previously_insured[df_sample_male_not_driving_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "        df_sample_male_not_driving_not_previously_insured_less1 = df_sample_male_not_driving_not_previously_insured[df_sample_male_not_driving_not_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_male_not_driving_not_previously_insured_1to2 = df_sample_male_not_driving_not_previously_insured[df_sample_male_not_driving_not_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_male_not_driving_not_previously_insured_more2 = df_sample_male_not_driving_not_previously_insured[df_sample_male_not_driving_not_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "\n",
    "\n",
    "        df_sample_female_driving_previously_insured_less1 = df_sample_female_driving_previously_insured[df_sample_female_driving_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_female_driving_previously_insured_1to2 = df_sample_female_driving_previously_insured[df_sample_female_driving_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_female_driving_previously_insured_more2 = df_sample_female_driving_previously_insured[df_sample_female_driving_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "        df_sample_female_driving_not_previously_insured_less1 = df_sample_female_driving_not_previously_insured[df_sample_female_driving_not_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_female_driving_not_previously_insured_1to2 = df_sample_female_driving_not_previously_insured[df_sample_female_driving_not_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_female_driving_not_previously_insured_more2 = df_sample_female_driving_not_previously_insured[df_sample_female_driving_not_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "\n",
    "        df_sample_female_not_driving_previously_insured_less1 = df_sample_female_not_driving_previously_insured[df_sample_female_not_driving_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_female_not_driving_previously_insured_1to2 = df_sample_female_not_driving_previously_insured[df_sample_female_not_driving_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_female_not_driving_previously_insured_more2 = df_sample_female_not_driving_previously_insured[df_sample_female_not_driving_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "        df_sample_female_not_driving_not_previously_insured_less1 = df_sample_female_not_driving_not_previously_insured[df_sample_female_not_driving_not_previously_insured['Vehicle_Age'] == 0]\n",
    "        df_sample_female_not_driving_not_previously_insured_1to2 = df_sample_female_not_driving_not_previously_insured[df_sample_female_not_driving_not_previously_insured['Vehicle_Age'] == 1]\n",
    "        df_sample_female_not_driving_not_previously_insured_more2 = df_sample_female_not_driving_not_previously_insured[df_sample_female_not_driving_not_previously_insured['Vehicle_Age'] == 2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Based on Vehicle Damage          \n",
    "        df_sample_male_driving_previously_insured_less1_damage                            = df_sample_male_driving_previously_insured_less1[df_sample_male_driving_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_previously_insured_less1_nodamage                          = df_sample_male_driving_previously_insured_less1[df_sample_male_driving_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "                            \n",
    "        df_sample_male_driving_previously_insured_1to2_damage                             = df_sample_male_driving_previously_insured_1to2[df_sample_male_driving_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_previously_insured_1to2_nodamage                           = df_sample_male_driving_previously_insured_1to2[df_sample_male_driving_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "                            \n",
    "        df_sample_male_driving_previously_insured_more2_damage                            = df_sample_male_driving_previously_insured_more2[df_sample_male_driving_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_previously_insured_more2_nodamage                          = df_sample_male_driving_previously_insured_more2[df_sample_male_driving_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "                        \n",
    "        df_sample_male_driving_not_previously_insured_less1_damage                        = df_sample_male_driving_not_previously_insured_less1[df_sample_male_driving_not_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_not_previously_insured_less1_nodamage                      = df_sample_male_driving_not_previously_insured_less1[df_sample_male_driving_not_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_male_driving_not_previously_insured_1to2_damage                         = df_sample_male_driving_not_previously_insured_1to2[df_sample_male_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_not_previously_insured_1to2_nodamage                       = df_sample_male_driving_not_previously_insured_1to2[df_sample_male_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_male_driving_not_previously_insured_more2_damage                        = df_sample_male_driving_not_previously_insured_more2[df_sample_male_driving_not_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_driving_not_previously_insured_more2_nodamage                      = df_sample_male_driving_not_previously_insured_more2[df_sample_male_driving_not_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "        df_sample_male_not_driving_previously_insured_less1_damage                        = df_sample_male_not_driving_previously_insured_less1[df_sample_male_not_driving_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_previously_insured_less1_nodamage                      = df_sample_male_not_driving_previously_insured_less1[df_sample_male_not_driving_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_male_not_driving_previously_insured_1to2_damage                         = df_sample_male_not_driving_previously_insured_1to2[df_sample_male_not_driving_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_previously_insured_1to2_nodamage                       = df_sample_male_not_driving_previously_insured_1to2[df_sample_male_not_driving_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_male_not_driving_previously_insured_more2_damage                        = df_sample_male_not_driving_previously_insured_more2[df_sample_male_not_driving_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_previously_insured_more2_nodamage                      = df_sample_male_not_driving_previously_insured_more2[df_sample_male_not_driving_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "\n",
    "        df_sample_male_not_driving_not_previously_insured_less1_damage                    = df_sample_male_not_driving_not_previously_insured_less1[df_sample_male_not_driving_not_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_not_previously_insured_less1_nodamage                  = df_sample_male_not_driving_not_previously_insured_less1[df_sample_male_not_driving_not_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_male_not_driving_not_previously_insured_1to2_damage                     = df_sample_male_not_driving_not_previously_insured_1to2[df_sample_male_not_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_not_previously_insured_1to2_nodamage                   = df_sample_male_not_driving_not_previously_insured_1to2[df_sample_male_not_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_male_not_driving_not_previously_insured_more2_damage                    = df_sample_male_not_driving_not_previously_insured_more2[df_sample_male_not_driving_not_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_male_not_driving_not_previously_insured_more2_nodamage                  = df_sample_male_not_driving_not_previously_insured_more2[df_sample_male_not_driving_not_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "        df_sample_female_driving_previously_insured_less1_damage                          = df_sample_female_driving_previously_insured_less1[df_sample_female_driving_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_previously_insured_less1_nodamage                        = df_sample_female_driving_previously_insured_less1[df_sample_female_driving_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_female_driving_previously_insured_1to2_damage                           = df_sample_female_driving_previously_insured_1to2[df_sample_female_driving_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_previously_insured_1to2_nodamage                         = df_sample_female_driving_previously_insured_1to2[df_sample_female_driving_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_female_driving_previously_insured_more2_damage                          = df_sample_female_driving_previously_insured_more2[df_sample_female_driving_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_previously_insured_more2_nodamage                        = df_sample_female_driving_previously_insured_more2[df_sample_female_driving_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "                        \n",
    "        df_sample_female_driving_not_previously_insured_less1_damage                      = df_sample_female_driving_not_previously_insured_less1[df_sample_female_driving_not_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_not_previously_insured_less1_nodamage                    = df_sample_female_driving_not_previously_insured_less1[df_sample_female_driving_not_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_female_driving_not_previously_insured_1to2_damage                       = df_sample_female_driving_not_previously_insured_1to2[df_sample_female_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_not_previously_insured_1to2_nodamage                     = df_sample_female_driving_not_previously_insured_1to2[df_sample_female_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_female_driving_not_previously_insured_more2_damage                      = df_sample_female_driving_not_previously_insured_more2[df_sample_female_driving_not_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_driving_not_previously_insured_more2_nodamage                    = df_sample_female_driving_not_previously_insured_more2[df_sample_female_driving_not_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "            \n",
    "            \n",
    "        df_sample_female_not_driving_previously_insured_less1_damage                      = df_sample_female_not_driving_previously_insured_less1[df_sample_female_not_driving_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_previously_insured_less1_nodamage                    = df_sample_female_not_driving_previously_insured_less1[df_sample_female_not_driving_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_female_not_driving_previously_insured_1to2_damage                       = df_sample_female_not_driving_previously_insured_1to2[df_sample_female_not_driving_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_previously_insured_1to2_nodamage                     = df_sample_female_not_driving_previously_insured_1to2[df_sample_female_not_driving_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "            \n",
    "        df_sample_female_not_driving_previously_insured_more2_damage                      = df_sample_female_not_driving_previously_insured_more2[df_sample_female_not_driving_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_previously_insured_more2_nodamage                    = df_sample_female_not_driving_previously_insured_more2[df_sample_female_not_driving_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "\n",
    "\n",
    "        \n",
    "        df_sample_female_not_driving_not_previously_insured_less1_damage                  = df_sample_female_not_driving_not_previously_insured_less1[df_sample_female_not_driving_not_previously_insured_less1['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_not_previously_insured_less1_nodamage                = df_sample_female_not_driving_not_previously_insured_less1[df_sample_female_not_driving_not_previously_insured_less1['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_female_not_driving_not_previously_insured_1to2_damage                   = df_sample_female_not_driving_not_previously_insured_1to2[df_sample_female_not_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_not_previously_insured_1to2_nodamage                 = df_sample_female_not_driving_not_previously_insured_1to2[df_sample_female_not_driving_not_previously_insured_1to2['Vehicle_Damage'] == 'No']\n",
    "                        \n",
    "        df_sample_female_not_driving_not_previously_insured_more2_damage                  = df_sample_female_not_driving_not_previously_insured_more2[df_sample_female_not_driving_not_previously_insured_more2['Vehicle_Damage'] == 'Yes']\n",
    "        df_sample_female_not_driving_not_previously_insured_more2_nodamage                = df_sample_female_not_driving_not_previously_insured_more2[df_sample_female_not_driving_not_previously_insured_more2['Vehicle_Damage'] == 'No']\n",
    "\n",
    "\n",
    "        return [df_sample_male_driving_previously_insured_less1_damage                         \n",
    "        ,df_sample_male_driving_previously_insured_less1_nodamage                       \n",
    "                            \n",
    "        ,df_sample_male_driving_previously_insured_1to2_damage                          \n",
    "        ,df_sample_male_driving_previously_insured_1to2_nodamage                        \n",
    "                            \n",
    "        ,df_sample_male_driving_previously_insured_more2_damage                         \n",
    "        ,df_sample_male_driving_previously_insured_more2_nodamage                       \n",
    "                        \n",
    "                        \n",
    "        ,df_sample_male_driving_not_previously_insured_less1_damage                     \n",
    "        ,df_sample_male_driving_not_previously_insured_less1_nodamage                   \n",
    "                        \n",
    "        ,df_sample_male_driving_not_previously_insured_1to2_damage                      \n",
    "        ,df_sample_male_driving_not_previously_insured_1to2_nodamage                    \n",
    "                        \n",
    "        ,df_sample_male_driving_not_previously_insured_more2_damage                     \n",
    "        ,df_sample_male_driving_not_previously_insured_more2_nodamage                   \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "        ,df_sample_male_not_driving_previously_insured_less1_damage                     \n",
    "        ,df_sample_male_not_driving_previously_insured_less1_nodamage                   \n",
    "                        \n",
    "        ,df_sample_male_not_driving_previously_insured_1to2_damage                      \n",
    "        ,df_sample_male_not_driving_previously_insured_1to2_nodamage                    \n",
    "                        \n",
    "        ,df_sample_male_not_driving_previously_insured_more2_damage                     \n",
    "        ,df_sample_male_not_driving_previously_insured_more2_nodamage                   \n",
    "                        \n",
    "\n",
    "        ,df_sample_male_not_driving_not_previously_insured_less1_damage                 \n",
    "        ,df_sample_male_not_driving_not_previously_insured_less1_nodamage               \n",
    "            \n",
    "        ,df_sample_male_not_driving_not_previously_insured_1to2_damage                  \n",
    "        ,df_sample_male_not_driving_not_previously_insured_1to2_nodamage                \n",
    "            \n",
    "        ,df_sample_male_not_driving_not_previously_insured_more2_damage                 \n",
    "        ,df_sample_male_not_driving_not_previously_insured_more2_nodamage               \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "        ,df_sample_female_driving_previously_insured_less1_damage                       \n",
    "        ,df_sample_female_driving_previously_insured_less1_nodamage                     \n",
    "                        \n",
    "        ,df_sample_female_driving_previously_insured_1to2_damage                        \n",
    "        ,df_sample_female_driving_previously_insured_1to2_nodamage                      \n",
    "                        \n",
    "        ,df_sample_female_driving_previously_insured_more2_damage                       \n",
    "        ,df_sample_female_driving_previously_insured_more2_nodamage                     \n",
    "                        \n",
    "                        \n",
    "        ,df_sample_female_driving_not_previously_insured_less1_damage                   \n",
    "        ,df_sample_female_driving_not_previously_insured_less1_nodamage                 \n",
    "            \n",
    "        ,df_sample_female_driving_not_previously_insured_1to2_damage                    \n",
    "        ,df_sample_female_driving_not_previously_insured_1to2_nodamage                  \n",
    "            \n",
    "        ,df_sample_female_driving_not_previously_insured_more2_damage                   \n",
    "        ,df_sample_female_driving_not_previously_insured_more2_nodamage                 \n",
    "            \n",
    "            \n",
    "            \n",
    "        ,df_sample_female_not_driving_previously_insured_less1_damage                   \n",
    "        ,df_sample_female_not_driving_previously_insured_less1_nodamage                 \n",
    "            \n",
    "        ,df_sample_female_not_driving_previously_insured_1to2_damage                    \n",
    "        ,df_sample_female_not_driving_previously_insured_1to2_nodamage                  \n",
    "            \n",
    "        ,df_sample_female_not_driving_previously_insured_more2_damage                   \n",
    "        ,df_sample_female_not_driving_previously_insured_more2_nodamage                 \n",
    "\n",
    "\n",
    "        \n",
    "        ,df_sample_female_not_driving_not_previously_insured_less1_damage               \n",
    "        ,df_sample_female_not_driving_not_previously_insured_less1_nodamage             \n",
    "                        \n",
    "        ,df_sample_female_not_driving_not_previously_insured_1to2_damage                \n",
    "        ,df_sample_female_not_driving_not_previously_insured_1to2_nodamage              \n",
    "                        \n",
    "        ,df_sample_female_not_driving_not_previously_insured_more2_damage               \n",
    "        ,df_sample_female_not_driving_not_previously_insured_more2_nodamage], [\"df_sample_male_driving_previously_insured_less1_damage\"                         \n",
    "        ,\"df_sample_male_driving_previously_insured_less1_nodamage\"                       \n",
    "                            \n",
    "        ,\"df_sample_male_driving_previously_insured_1to2_damage\"                          \n",
    "        ,\"df_sample_male_driving_previously_insured_1to2_nodamage\"                        \n",
    "                            \n",
    "        ,\"df_sample_male_driving_previously_insured_more2_damage\"                         \n",
    "        ,\"df_sample_male_driving_previously_insured_more2_nodamage\"                       \n",
    "                        \n",
    "                        \n",
    "        ,\"df_sample_male_driving_not_previously_insured_less1_damage\"                     \n",
    "        ,\"df_sample_male_driving_not_previously_insured_less1_nodamage\"                   \n",
    "                        \n",
    "        ,\"df_sample_male_driving_not_previously_insured_1to2_damage\"                      \n",
    "        ,\"df_sample_male_driving_not_previously_insured_1to2_nodamage\"                    \n",
    "                        \n",
    "        ,\"df_sample_male_driving_not_previously_insured_more2_damage\"                     \n",
    "        ,\"df_sample_male_driving_not_previously_insured_more2_nodamage\"                   \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "        ,\"df_sample_male_not_driving_previously_insured_less1_damage\"                     \n",
    "        ,\"df_sample_male_not_driving_previously_insured_less1_nodamage\"                   \n",
    "                        \n",
    "        ,\"df_sample_male_not_driving_previously_insured_1to2_damage\"                      \n",
    "        ,\"df_sample_male_not_driving_previously_insured_1to2_nodamage\"                    \n",
    "                        \n",
    "        ,\"df_sample_male_not_driving_previously_insured_more2_damage\"                     \n",
    "        ,\"df_sample_male_not_driving_previously_insured_more2_nodamage\"                   \n",
    "                        \n",
    "\n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_less1_damage\"                 \n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_less1_nodamage\"               \n",
    "            \n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_1to2_damage\"                  \n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_1to2_nodamage\"                \n",
    "            \n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_more2_damage\"                 \n",
    "        ,\"df_sample_male_not_driving_not_previously_insured_more2_nodamage\"               \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "        ,\"df_sample_female_driving_previously_insured_less1_damage\"                       \n",
    "        ,\"df_sample_female_driving_previously_insured_less1_nodamage\"                     \n",
    "                        \n",
    "        ,\"df_sample_female_driving_previously_insured_1to2_damage\"                        \n",
    "        ,\"df_sample_female_driving_previously_insured_1to2_nodamage\"                      \n",
    "                        \n",
    "        ,\"df_sample_female_driving_previously_insured_more2_damage\"                       \n",
    "        ,\"df_sample_female_driving_previously_insured_more2_nodamage\"                     \n",
    "                        \n",
    "                        \n",
    "        ,\"df_sample_female_driving_not_previously_insured_less1_damage\"                   \n",
    "        ,\"df_sample_female_driving_not_previously_insured_less1_nodamage\"                 \n",
    "            \n",
    "        ,\"df_sample_female_driving_not_previously_insured_1to2_damage\"                    \n",
    "        ,\"df_sample_female_driving_not_previously_insured_1to2_nodamage\"                  \n",
    "            \n",
    "        ,\"df_sample_female_driving_not_previously_insured_more2_damage\"                   \n",
    "        ,\"df_sample_female_driving_not_previously_insured_more2_nodamage\"                 \n",
    "            \n",
    "            \n",
    "            \n",
    "        ,\"df_sample_female_not_driving_previously_insured_less1_damage\"                   \n",
    "        ,\"df_sample_female_not_driving_previously_insured_less1_nodamage\"                 \n",
    "            \n",
    "        ,\"df_sample_female_not_driving_previously_insured_1to2_damage\"                    \n",
    "        ,\"df_sample_female_not_driving_previously_insured_1to2_nodamage\"                  \n",
    "            \n",
    "        ,\"df_sample_female_not_driving_previously_insured_more2_damage\"                   \n",
    "        ,\"df_sample_female_not_driving_previously_insured_more2_nodamage\"                 \n",
    "\n",
    "\n",
    "        \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_less1_damage\"               \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_less1_nodamage\"             \n",
    "                        \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_1to2_damage\"                \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_1to2_nodamage\"              \n",
    "                        \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_more2_damage\"               \n",
    "        ,\"df_sample_female_not_driving_not_previously_insured_more2_nodamage\"], \n",
    "\n",
    "    def majority_clusters(self,threshold_percentage=1):\n",
    "        sample_size = len(self.df_sample)\n",
    "        All_clusters,All_cluster_names = self.all_clusters()\n",
    "        majority_clusters = []\n",
    "        majority_clusters_names = []\n",
    "\n",
    "        for i in range(len(All_clusters)):\n",
    "            if len(All_clusters[i]) > threshold_percentage*sample_size/100:\n",
    "                majority_clusters.append(All_clusters[i])\n",
    "                majority_clusters_names.append(All_cluster_names[i])\n",
    "\n",
    "        return majority_clusters,majority_clusters_names \n",
    "\n",
    "    def good_clusters(self,hope_percentage=1):\n",
    "        majority_clusters,majority_clusters_names = self.majority_clusters(threshold_percentage=1)\n",
    "        hope_percentage = 1\n",
    "        good_clusters = []\n",
    "        good_cluster_names = []\n",
    "        for i in range(len(majority_clusters)):\n",
    "            positive = len(majority_clusters[i][majority_clusters[i][\"Response\"]==1])\n",
    "            negative = len(majority_clusters[i][majority_clusters[i][\"Response\"]==0])\n",
    "            success_chance=positive*100/(positive+negative)\n",
    "\n",
    "            if success_chance>hope_percentage:\n",
    "                good_clusters.append(majority_clusters[i])\n",
    "                good_cluster_names.append(majority_clusters_names[i])\n",
    "            else:\n",
    "                pass\n",
    "        return good_clusters, good_cluster_names                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_cleaning():\n",
    "    def clean_single_cluster(self,df_sample):\n",
    "        #dropping categorical columns that are not needed\n",
    "        df_sample_cleaned = df_sample.drop(['Gender','Driving_License','Previously_Insured','Vehicle_Age','Vehicle_Damage'],axis=1)\n",
    "        return df_sample_cleaned\n",
    "\n",
    "    def clean_multiple_cluster(self,cluster_group):\n",
    "        cleaned_clusters = []\n",
    "        for i in range(len(cluster_group)):\n",
    "            clear_output = self.clean_single_cluster(cluster_group[i])\n",
    "            cleaned_clusters.append(clear_output)\n",
    "        \n",
    "        return cleaned_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model training start from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clustering(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters, all_cluster_names = clusters.all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cluster = data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all_clusters = cleaned_cluster.clean_multiple_cluster(all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = cleaned_all_clusters[0]\n",
    "scalar = MinMaxScaler()\n",
    "Y=df_model[\"Response\"]\n",
    "x=df_model.drop(columns=[\"Response\",\"id\"],axis=1)\n",
    "x = scalar.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cluster 0\n",
      "Finished with cluseter 0\n",
      "training on cluster 1\n",
      "Finished with cluseter 1\n",
      "training on cluster 2\n",
      "Finished with cluseter 2\n",
      "training on cluster 3\n",
      "Finished with cluseter 3\n",
      "training on cluster 4\n",
      "Finished with cluseter 4\n",
      "training on cluster 5\n",
      "Finished with cluseter 5\n",
      "training on cluster 6\n",
      "Finished with cluseter 6\n",
      "training on cluster 7\n",
      "Finished with cluseter 7\n",
      "training on cluster 8\n",
      "Finished with cluseter 8\n",
      "training on cluster 9\n",
      "Finished with cluseter 9\n",
      "training on cluster 10\n",
      "Finished with cluseter 10\n",
      "training on cluster 11\n",
      "Finished with cluseter 11\n",
      "training on cluster 12\n",
      "Filed for cluster 12\n",
      "training on cluster 13\n",
      "Finished with cluseter 13\n",
      "training on cluster 14\n",
      "Finished with cluseter 14\n",
      "training on cluster 15\n",
      "Finished with cluseter 15\n",
      "training on cluster 16\n",
      "Finished with cluseter 16\n",
      "training on cluster 17\n",
      "Filed for cluster 17\n",
      "training on cluster 18\n",
      "Finished with cluseter 18\n",
      "training on cluster 19\n",
      "Finished with cluseter 19\n",
      "training on cluster 20\n",
      "Finished with cluseter 20\n",
      "training on cluster 21\n",
      "Finished with cluseter 21\n",
      "training on cluster 22\n",
      "Finished with cluseter 22\n",
      "training on cluster 23\n",
      "Finished with cluseter 23\n",
      "training on cluster 24\n",
      "Finished with cluseter 24\n",
      "training on cluster 25\n",
      "Finished with cluseter 25\n",
      "training on cluster 26\n",
      "Finished with cluseter 26\n",
      "training on cluster 27\n",
      "Finished with cluseter 27\n",
      "training on cluster 28\n",
      "Finished with cluseter 28\n",
      "training on cluster 29\n",
      "Finished with cluseter 29\n",
      "training on cluster 30\n",
      "Finished with cluseter 30\n",
      "training on cluster 31\n",
      "Finished with cluseter 31\n",
      "training on cluster 32\n",
      "Finished with cluseter 32\n",
      "training on cluster 33\n",
      "Finished with cluseter 33\n",
      "training on cluster 34\n",
      "Finished with cluseter 34\n",
      "training on cluster 35\n",
      "Finished with cluseter 35\n",
      "training on cluster 36\n",
      "Finished with cluseter 36\n",
      "training on cluster 37\n",
      "Finished with cluseter 37\n",
      "training on cluster 38\n",
      "Finished with cluseter 38\n",
      "training on cluster 39\n",
      "Finished with cluseter 39\n",
      "training on cluster 40\n",
      "Finished with cluseter 40\n",
      "training on cluster 41\n",
      "Finished with cluseter 41\n",
      "training on cluster 42\n",
      "Finished with cluseter 42\n",
      "training on cluster 43\n",
      "Finished with cluseter 43\n",
      "training on cluster 44\n",
      "Finished with cluseter 44\n",
      "training on cluster 45\n",
      "Finished with cluseter 45\n",
      "training on cluster 46\n",
      "Finished with cluseter 46\n",
      "training on cluster 47\n",
      "Filed for cluster 47\n"
     ]
    }
   ],
   "source": [
    "for cluster_number in range(len(all_clusters)):\n",
    "    try: \n",
    "        print(\"training on cluster {}\".format(cluster_number))\n",
    "        df_model = cleaned_all_clusters[cluster_number]\n",
    "        scalar = MinMaxScaler()\n",
    "        Y=df_model[\"Response\"]\n",
    "        x=df_model.drop(columns=[\"Response\",\"id\"],axis=1)\n",
    "        x = scalar.fit_transform(x)\n",
    "        rdf = RandomForestClassifier(n_estimators=100,max_depth=10,class_weight={0:0.3,1:0.7})\n",
    "        rdf.fit(x, Y)\n",
    "        model_path = r'C:\\Users\\malik\\Desktop\\kaggle compitition\\model_for_each_cluster\\model_for_cluster_{}.pkl'.format(cluster_number)\n",
    "        dump(rdf, model_path)\n",
    "        print(\"Finished with cluseter {}\".format(cluster_number))\n",
    "    except:\n",
    "        print(\"Filed for cluster {}\".format(cluster_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r'data\\playground-series-s4e7\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clustering(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_clusters,all_test_clusters_names = clusters.all_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cluster = data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all_test_clusters = cleaned_cluster.clean_multiple_cluster(all_test_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>11505010</td>\n",
       "      <td>23</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28288.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>11505273</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25903.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>11505512</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>11505604</td>\n",
       "      <td>20</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>11506152</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668811</th>\n",
       "      <td>19173609</td>\n",
       "      <td>27</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27229.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668847</th>\n",
       "      <td>19173645</td>\n",
       "      <td>25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35620.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668874</th>\n",
       "      <td>19173672</td>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23260.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669210</th>\n",
       "      <td>19174008</td>\n",
       "      <td>20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669506</th>\n",
       "      <td>19174304</td>\n",
       "      <td>22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36269.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35447 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Age  Region_Code  Annual_Premium  Policy_Sales_Channel  \\\n",
       "212      11505010   23         28.0         28288.0                 153.0   \n",
       "475      11505273   22         22.0         25903.0                 152.0   \n",
       "714      11505512   27          3.0          2630.0                 156.0   \n",
       "806      11505604   20         41.0          2630.0                 160.0   \n",
       "1354     11506152   27          3.0          2630.0                 157.0   \n",
       "...           ...  ...          ...             ...                   ...   \n",
       "7668811  19173609   27         18.0         27229.0                 152.0   \n",
       "7668847  19173645   25         12.0         35620.0                  26.0   \n",
       "7668874  19173672   24         13.0         23260.0                 152.0   \n",
       "7669210  19174008   20         11.0          2630.0                 160.0   \n",
       "7669506  19174304   22          8.0         36269.0                 155.0   \n",
       "\n",
       "         Vintage  \n",
       "212          292  \n",
       "475          189  \n",
       "714          125  \n",
       "806          158  \n",
       "1354         113  \n",
       "...          ...  \n",
       "7668811      148  \n",
       "7668847      105  \n",
       "7668874      101  \n",
       "7669210      117  \n",
       "7669506       98  \n",
       "\n",
       "[35447 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_all_test_clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions on cluster 0\n",
      "Finished with cluseter 0\n",
      "making predictions on cluster 1\n",
      "Finished with cluseter 1\n",
      "making predictions on cluster 2\n",
      "Finished with cluseter 2\n",
      "making predictions on cluster 3\n",
      "Finished with cluseter 3\n",
      "making predictions on cluster 4\n",
      "Finished with cluseter 4\n",
      "making predictions on cluster 5\n",
      "Failed for cluster 5. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 6\n",
      "Finished with cluseter 6\n",
      "making predictions on cluster 7\n",
      "Finished with cluseter 7\n",
      "making predictions on cluster 8\n",
      "Finished with cluseter 8\n",
      "making predictions on cluster 9\n",
      "Finished with cluseter 9\n",
      "making predictions on cluster 10\n",
      "Finished with cluseter 10\n",
      "making predictions on cluster 11\n",
      "Finished with cluseter 11\n",
      "making predictions on cluster 12\n",
      "Failed for cluster 12. [Errno 2] No such file or directory: 'C:\\\\Users\\\\malik\\\\Desktop\\\\kaggle compitition\\\\model_for_each_cluster\\\\model_for_cluster_12.pkl'\n",
      "making predictions on cluster 13\n",
      "Failed for cluster 13. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 14\n",
      "Finished with cluseter 14\n",
      "making predictions on cluster 15\n",
      "Finished with cluseter 15\n",
      "making predictions on cluster 16\n",
      "Finished with cluseter 16\n",
      "making predictions on cluster 17\n",
      "Failed for cluster 17. [Errno 2] No such file or directory: 'C:\\\\Users\\\\malik\\\\Desktop\\\\kaggle compitition\\\\model_for_each_cluster\\\\model_for_cluster_17.pkl'\n",
      "making predictions on cluster 18\n",
      "Finished with cluseter 18\n",
      "making predictions on cluster 19\n",
      "Failed for cluster 19. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 20\n",
      "Finished with cluseter 20\n",
      "making predictions on cluster 21\n",
      "Finished with cluseter 21\n",
      "making predictions on cluster 22\n",
      "Finished with cluseter 22\n",
      "making predictions on cluster 23\n",
      "Failed for cluster 23. Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MinMaxScaler.\n",
      "making predictions on cluster 24\n",
      "Finished with cluseter 24\n",
      "making predictions on cluster 25\n",
      "Finished with cluseter 25\n",
      "making predictions on cluster 26\n",
      "Finished with cluseter 26\n",
      "making predictions on cluster 27\n",
      "Finished with cluseter 27\n",
      "making predictions on cluster 28\n",
      "Finished with cluseter 28\n",
      "making predictions on cluster 29\n",
      "Failed for cluster 29. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 30\n",
      "Finished with cluseter 30\n",
      "making predictions on cluster 31\n",
      "Finished with cluseter 31\n",
      "making predictions on cluster 32\n",
      "Finished with cluseter 32\n",
      "making predictions on cluster 33\n",
      "Finished with cluseter 33\n",
      "making predictions on cluster 34\n",
      "Finished with cluseter 34\n",
      "making predictions on cluster 35\n",
      "Finished with cluseter 35\n",
      "making predictions on cluster 36\n",
      "Failed for cluster 36. Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MinMaxScaler.\n",
      "making predictions on cluster 37\n",
      "Failed for cluster 37. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 38\n",
      "Finished with cluseter 38\n",
      "making predictions on cluster 39\n",
      "Failed for cluster 39. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 40\n",
      "Failed for cluster 40. Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MinMaxScaler.\n",
      "making predictions on cluster 41\n",
      "Failed for cluster 41. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 42\n",
      "Finished with cluseter 42\n",
      "making predictions on cluster 43\n",
      "Failed for cluster 43. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 44\n",
      "Finished with cluseter 44\n",
      "making predictions on cluster 45\n",
      "Failed for cluster 45. index 1 is out of bounds for axis 1 with size 1\n",
      "making predictions on cluster 46\n",
      "Finished with cluseter 46\n",
      "making predictions on cluster 47\n",
      "Failed for cluster 47. Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required by MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for cluster_number in range(len(all_clusters)):\n",
    "    try: \n",
    "        print(\"making predictions on cluster {}\".format(cluster_number))\n",
    "        df_model = cleaned_all_test_clusters[cluster_number]\n",
    "        x=df_model.drop(columns=[\"id\"],axis=1)\n",
    "        x = scalar.fit_transform(x)\n",
    "        model_path = r'C:\\Users\\malik\\Desktop\\kaggle compitition\\model_for_each_cluster\\model_for_cluster_{}.pkl'.format(cluster_number)\n",
    "        cluster_model = load(model_path)\n",
    "        y_predicted = cluster_model.predict_proba(x)[:, 1]\n",
    "        df_model[\"Response\"] = y_predicted\n",
    "        predictions.append(df_model)\n",
    "        print(\"Finished with cluseter {}\".format(cluster_number))\n",
    "    except Exception as e :\n",
    "        print(\"Failed for cluster {}. {}\".format(cluster_number,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11504803</td>\n",
       "      <td>22</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25715.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>245</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11504807</td>\n",
       "      <td>33</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46937.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11504822</td>\n",
       "      <td>24</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>282</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11504834</td>\n",
       "      <td>25</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29077.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11504890</td>\n",
       "      <td>27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38066.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669840</th>\n",
       "      <td>19174638</td>\n",
       "      <td>25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25015.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>226</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669849</th>\n",
       "      <td>19174647</td>\n",
       "      <td>29</td>\n",
       "      <td>28.0</td>\n",
       "      <td>43394.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669856</th>\n",
       "      <td>19174654</td>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34334.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669862</th>\n",
       "      <td>19174660</td>\n",
       "      <td>28</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25651.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>184</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669865</th>\n",
       "      <td>19174663</td>\n",
       "      <td>23</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27498.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>946778 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Age  Region_Code  Annual_Premium  Policy_Sales_Channel  \\\n",
       "5        11504803   22         30.0         25715.0                 152.0   \n",
       "9        11504807   33         28.0         46937.0                 152.0   \n",
       "24       11504822   24         41.0         40900.0                 152.0   \n",
       "36       11504834   25         29.0         29077.0                 152.0   \n",
       "92       11504890   27          8.0         38066.0                 152.0   \n",
       "...           ...  ...          ...             ...                   ...   \n",
       "7669840  19174638   25         14.0         25015.0                 152.0   \n",
       "7669849  19174647   29         28.0         43394.0                 152.0   \n",
       "7669856  19174654   24          8.0         34334.0                 152.0   \n",
       "7669862  19174660   28         50.0         25651.0                 152.0   \n",
       "7669865  19174663   23         46.0         27498.0                 152.0   \n",
       "\n",
       "         Vintage  Response  \n",
       "5            245  0.000367  \n",
       "9             72  0.000307  \n",
       "24           282  0.000350  \n",
       "36            55  0.000327  \n",
       "92            71  0.000158  \n",
       "...          ...       ...  \n",
       "7669840      226  0.000539  \n",
       "7669849       92  0.000367  \n",
       "7669856       82  0.000159  \n",
       "7669862      184  0.000181  \n",
       "7669865       79  0.000116  \n",
       "\n",
       "[946778 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[[\"id\",\"Response\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values(by=\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11504798</td>\n",
       "      <td>0.024502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11504799</td>\n",
       "      <td>0.493929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11504800</td>\n",
       "      <td>0.471456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11504801</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11504802</td>\n",
       "      <td>0.083151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669861</th>\n",
       "      <td>19174659</td>\n",
       "      <td>0.366842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669862</th>\n",
       "      <td>19174660</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669863</th>\n",
       "      <td>19174661</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669864</th>\n",
       "      <td>19174662</td>\n",
       "      <td>0.703514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669865</th>\n",
       "      <td>19174663</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7668359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Response\n",
       "0        11504798  0.024502\n",
       "1        11504799  0.493929\n",
       "2        11504800  0.471456\n",
       "3        11504801  0.000150\n",
       "4        11504802  0.083151\n",
       "...           ...       ...\n",
       "7669861  19174659  0.366842\n",
       "7669862  19174660  0.000181\n",
       "7669863  19174661  0.000713\n",
       "7669864  19174662  0.703514\n",
       "7669865  19174663  0.000116\n",
       "\n",
       "[7668359 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.concat([df_test,df_final],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission[\"Response\"].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display first and last column of the data frame\n",
    "df_submission[[\"id\",\"Response\"]].to_csv(r'C:\\Users\\malik\\Desktop\\kaggle compitition\\submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(r'C:\\Users\\malik\\Desktop\\kaggle compitition\\submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.drop(columns=[\"id.1\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(r'C:\\Users\\malik\\Desktop\\kaggle compitition\\submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
